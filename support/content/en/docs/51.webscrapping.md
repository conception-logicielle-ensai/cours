---
url: /docs/webscrapping/
title: üì§ Webscrapping et requ√™tes c√¥t√© client.
---
## ‚ö†Ô∏è C'est en travaux, revenez plus tard !

Notre page est actuellement en cours d'√©criture et nous mettons tout en ≈ìuvre pour vous offrir la meilleure exp√©rience possible. Nous vous prions de bien vouloir patienter, elle sera remplie prochainement.

## Traitement du contenu des sites web : cas d'√©cole du parsing de string

La r√©cup√©ration des donn√©es issues d'un site au format `html` est possible par diff√©rents outils de type client `HTTP`. Ces donn√©es ne sont pas exploitables telles quelles, elle n√©cessitent a minima un retraitement par rapport a tous les √©l√©ments d'affichage inutiles pour l'exploitation des donn√©es.

Ce retraitement peut se fait de mani√®re manuelle dans les str, avec les fonctions `split` ou `find`

exemple pour r√©cup√©rer le nombre de parties du cours envoy√©es sur le site : 
```python
import requests

reponse_requete_http = requests.get("https://conception-logicielle.abrunetti.fr/cours-2024/")
r = requests.get(url)
html = r.text
url = "http://localhost:1313/cours-2024/"
get_h2_parties_du_cours_beginning_index = html.find("<h2 id=\"parties-du-cours\"")
html_apres_parties = html[get_h2_parties_du_cours_beginning_index::]
get_liste_parties_du_cours_start_index = html_apres_parties.find("<ul>") + 4
get_liste_parties_du_cours_end_index = html_apres_parties.find("</ul>")
html_parties_du_cours = html_apres_parties[get_liste_parties_du_cours_start_index:get_liste_parties_du_cours_end_index]
print("nombre de parties du cours : "+str(len(html_parties_du_cours.split("<li>")) - 1))
```


### Regex, Expressions r√©guli√®res : Isoler et capturer dans des chaines caract√®res

<img src="/img/webservice/regex.jpg">
Les expressions r√©guli√®res, ou regex pour faire court, sont des motifs que vous pouvez utiliser pour rechercher du texte dans une cha√Æne de caract√®res. 
On parle assez souvent de `pattern` `matching`. On va donc ici √©laborer des patterns pour r√©cup√©rer les ensembles coh√©rents de chaine de caract√®res qui respectent ce pattern.

Quel int√™ret ? Ici l'on va parcourir des balises html diverses `div` `ul` et l'on va vouloir par exemple r√©cup√©rer les m√©tadonn√©es contenues dans ces balises.

Python prend en charge les expressions r√©guli√®res gr√¢ce au module `re` d√©j√† pr√©sent dans sa biblioth√®que standard.

> C'est un concept qui est pr√©sent dans la plupart des languages. Il est donc r√©utilisable lors de probl√©matiques de traitement de donn√©es au format `str`

### Syntaxe 

| Ancres | Description                                               |
|--------|-----------------------------------------------------------|
| ^      | D√©but de ligne. Correspond au d√©but d'une cha√Æne de caract√®res. |
| $      | Fin de ligne. Correspond √† la fin d'une cha√Æne de caract√®res. |
| \b     | Limite de mot. Correspond √† la position entre un caract√®re de mot (\w) et un caract√®re qui n'est pas un caract√®re de mot. |

| Symbole sp√©cial | Description                                               |
|-----------------|-----------------------------------------------------------|
| .               | Correspond √† n'importe quel caract√®re, sauf un saut de ligne. |
| *               | Correspond √† z√©ro ou plusieurs occurrences du caract√®re pr√©c√©dent. |
| \d              | Correspond √† un chiffre. √âquivalent √† [0-9].              |
| \D              | Correspond √† tout caract√®re qui n'est pas un chiffre. √âquivalent √† [^0-9]. |
| \w              | Correspond √† un caract√®re alphanum√©rique (lettres, chiffres, soulign√©). √âquivalent √† [a-zA-Z0-9_]. |
| \W              | Correspond √† tout caract√®re qui n'est pas alphanum√©rique. √âquivalent √† [^a-zA-Z0-9_]. |
| \s              | Correspond √† un caract√®re d'espacement (espace, tabulation, retour √† la ligne). |
| \S              | Correspond √† tout caract√®re qui n'est pas un caract√®re d'espacement. |

Exemples d'utilisation : 

- **^abc** : Correspond √† la cha√Æne "abc" au d√©but de la ligne.
- **xyz$** : Correspond √† la cha√Æne "xyz" √† la fin de la ligne.
- **\d{3}** : Correspond √† trois chiffres cons√©cutifs.
- **\w+** : Correspond √† un ou plusieurs caract√®res alphanum√©riques.
- **^toto.*** r√©cup√®re toute la ligne si elle contient toto au d√©but
### Groupes de Capture :
Les groupes de capture sont utilis√©s pour capturer une partie sp√©cifique d'une correspondance d'expression r√©guli√®re. Ils sont d√©limit√©s par des parenth√®ses.

| Expression r√©guli√®re | Description                                |
|----------------------|--------------------------------------------|
| (.*)                 | Capture toute la chaine                    |
| `<li>(.*?)</li>`     | Capture tout ce qui est entre la balise li |

On peut ensuite utiliser les groupes de capture avec `\1` ou `\0`

Exemple avec le support du cours
```python
import requests
url = "https://conception-logicielle.abrunetti.fr/cours-2024/"
r = requests.get(url)
html = r.text
print(html)
import re
pattern_regex = "<li><a href=\/cours-2024/(.*?)\>"
matches = re.findall(pattern_regex,html)
print(matches)
# [' title=Cours', 'introduction', 'introduction', 'git/', 'portabilite/', 'qualite-automatisation/']
```
## Traitement des donn√©es avec un Parser HTML : Exemple de beautiful soup

<img src="/img/webservice/beautifulsoup.jpg">

Beautiful Soup permet d'encapsuler l'arborescence des √©l√©ments html dans un objet afin de pouvoir assez facilement le parcourir.

C'est une librairie externe on doit l'installer avec `pip` : `pip3 install beautifulsoup4`
```python
from bs4 import BeautifulSoup
import requests

url = "https://conception-logicielle.abrunetti.fr/cours-2024/"
res = requests.get(url)
html = res.text
soup = BeautifulSoup(html, "html.parser")
```

L'objectif de ce parser est de pouvoir r√©aliser du parsing de html et donc de s'abstraire de toutes les r√®gles de style interne a la page html elle m√™me. En effet, certains pourraient vouloir sauter des lignes pour s√©parer diff√©rentes sections alors que d'autres non. Cette information pollue la r√©cup√©ration de donn√©es et donc il est de bon ton de la contr√¥ler.

Ainsi une page comme celle ci : 

devient apr√®s parsing : 

Beautiful soup permet √©galement le requ√™tage des donn√©es r√©cup√©r√©es: 
```python
results = soup.find(id="ResultsContainer")
job_elements = results.find_all("div", class_="card-content")
title_element = job_element.find("h2", class_="title")
print(title_element.text)
```


<div class="alert alert-info">
  <strong> Pour aller plus loin </strong> <br/>
    Doc officielle : <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a>
</div>

## Automatisation avec Selenium

<img src="/img/webservice/selenium.webp">
Selenium est un outil qui permet d'executer des tests et des actions comme un robot sur des interfaces web. On peut l'utiliser aussi bien pour la r√©alisation de tests fonctionnels : `je me connecte a tel doctolib, je m'attends a trouver 10 profils diff√©rents de m√©decins dans l'affichage`

C'est un outil qui est tr√®s utilis√© dans diff√©rents languages : java, python, javascript,.. 

√ßa s'installe avec pip : `pip3 install selenium`

Regardons ensemble le **getting started** de la doc officielle : <a href="https://selenium-python.readthedocs.io/getting-started.html"> https://selenium-python.readthedocs.io/getting-started.html
</a>

## Travaux pratiques

- D√©couvrez les regex en r√©solvant le tutoriel de https://regexcrossword.com/
