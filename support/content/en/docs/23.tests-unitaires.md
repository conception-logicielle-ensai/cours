---
url: /docs/analyse-dynamique
title: üß™ Analyse dynamique du code
---
Pour s'assurer du bon fonctionnement d'une base de code, une bonne pratique est l'execution du code pour son analyse dynamique.
On peut l'executer de diff√©rentes mani√®res.

- Executer une fonction isol√©ment dans autres en controllant les input et en v√©rifiant qu'un output est bien l'attendu : on parle alors de tests unitaires.
- Executer un sc√©nario de test sur une chaine plus grande: si je demande confiture, alors l'application doit me renvoyer la bonne r√©ponse. On parle alors de tests d'int√©gration.
- Executer un sc√©nario de test concret: si je demande confiture, alors l'application doit me renvoyer la bonne r√©ponse. On parle alors de tests fonctionnels si on est dans un environnement ferm√© ou test end to end en condition r√©elle.
- Executer un sc√©nario de mont√©e en charge : Si toutes les secondes quelqu'un demande a mon application diff√©rents objets, est ce que l'application va tenir le coup ou est ce que le service va s'arr√™ter. On parle alors de test de charge.
- Executer un sc√©nario en √©valuant la performance : Si je demande a l'application de la confiture, elle doit me r√©pondre en moins de 1 secondes. C'est ici un test de performances.

## Tests unitaires

Les tests unitaires sont les tests des fonctions de mani√®re **isol√©e**. On entend ici de cette isolation que le contour des fonctions utilis√©es soit maitris√© et qu'il n'y ait pas de facteur ext√©rieur pouvant alt√©rer l'issue d'un test.

En cela, cela peut parfois √™tre assez laborieux de tester une fonction, puisque l'on veut pouvoir couvrir unitairement tous les **corner case** qu'elle recouvre.

> Exemple : pour une fonction qui renvoie la date du jour, l'on peut en effet v√©rifier qu'elle le fait selon le bon format, qu'elle le fait bien pour une ann√©e donn√©e et qu'elle renvoie une erreur si elle ne peut pas s'executer.

Pour ce qui est de la forme des tests, ils reposent sur des **assertions**: on souhaite valider le comportement d'une fonction au regard d'un attendu.

```python
assert sum([1, 2, 3]) == 6, "Should be 6")
```

Unittest impl√©mente un panel d'assertions que l'on peut faire.

L'usage le plus classique est le `assertEqual()`

Exemple :

```python
import unittest

def add(a, b):
    return a + b

class TestAdd(unittest.TestCase):
    def test_add(self):
        self.assertEqual(add(2, 3), 5)
        self.assertEqual(add(-2, 3), 1)
        self.assertEqual(add(2, -3), -1)
        self.assertEqual(add(-2, -3), -5)

if __name__ == '__main__':
    unittest.main()
```

> Unittest permet l'extension de sa classe TestCase pour r√©cup√©rer toutes les fonctions qui nous seront utiles dans le testing

Pour lancer les tests il faut effectuer la commande : 
`python3 -m unittest discover -s test -p "test_*.py"`
### Isolation des comportements : Mocking

En programmation , les mocks (simulacres ou mock object) sont des objets simul√©s qui reproduisent le comportement d'objets r√©els de mani√®re contr√¥l√©e.

L'int√™ret de ces simulacres, c'est que l'on peut du coup isoler les parties des tests, pour que notre test ne teste r√©ellement que la plus petite brique possible.

Un exemple :

J'utilise un webservice m√©t√©o pour r√©cup√©rer des infos, et ensuite effectuer un traitement sur ces donn√©es m√©t√©o.

- L'API peut √™tre indisponible, il faut donc un moyen r√©siliant de tester les fonctions qui l'utilisent.
- La m√©t√©o change, si je veux pouvoir tester que ma fonction **get_condition** fonctionne bien par rapport a des donn√©es, et donc mettre une clause fixe d'assertion, je suis bloqu√©. 

=> Mais je peux toujours faire en sorte d'interposer un wrapper qui me renvoie les donn√©es a un format connu.

La librairie unittest propose une impl√©mentation du concept de Mock.
Voici un exemple de ce que cela donnerait :

```python
import unittest
from unittest.mock import MagicMock
import requests

def get_condition(city):
    response = requests.get(f'https://weather.com/{city}')
    weather = response.json()
    return weather["condition"]

class TestWeatherApp(unittest.TestCase):
    def setUp(self):
        self.get_patcher = unittest.mock.patch('requests.get')
        self.mock_get = self.get_patcher.start()

    def tearDown(self):
        self.get_patcher.stop()

    def test_get_weather(self):
        self.mock_get.return_value.json.return_value = {'temperature': 72, 'condition': 'sunny'}
        weather = get_condition('San Francisco')
        self.assertEqual(weather, 'sunny')
```

> Pour les objets, il y a √©galement la possibilit√© d'utiliser MagicMock, ce qui vous permet de reconstruire un objet custom avec fonctions et retours custom

## Tests fonctionnels et End to End

L'id√©e des tests fonctionnels est de v√©rifier si l'application fonctionne et r√©pond a un besoin exprim√©.

Ils sont en g√©n√©ral sp√©cifi√©s comme des sc√©narios d'utilisation de l'application. Ils s'executent sur des environnements plus grands et sont donc plus difficiles a d√©finir (souvent pour des cas plus g√©n√©raux).

Typiquement cela reviendrait a lancer le serveur et a faire une requete dessus dans un processus parall√®le.

- Cela peut s'executer simplement directement avec des outils comme requests et unittest : 

```python
import unittest
import requests
class TestApi(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        import subprocess
        cls.apiprocess = subprocess.Popen(["uvicorn", "main:app"])
        cls.wait_for_api()
    @classmethod
    def tearDownClass(cls):
        cls.apiprocess.terminate()
    @classmethod
    def wait_for_api(cls):
        import time
        url = "http://localhost:8000/"
        delay = 1
        attempts = 100
        for _ in range(attempts):
            try:
                requests.get(url)
                break
            except requests.ConnectionError:
                time.sleep(delay)
        else:
            raise TimeoutError(f"API didn't start in {delay*attempts} seconds")
    def test_get_label_confiture_ok(self):
        response_http = requests.get("http://localhost:8000/")
        self.assertEqual(response_http.status_code,200)
```

Cela fonctionne pour une API. On pourrait √©galement utiliser l'impl√©mentation `TestClient` de FASTAPI our des tests fonctionnels et end to end (en condition r√©elles).

<div class="alert alert-info">
  <strong> Pour info </strong>:
  On verra la semaine prochaine l'outil selenium qui permet de tester les applications web et sites web. On aurait pu √©galement l'utiliser ici mais c'est un peu overkill. Selenium est un outil qui permet de simuler des comportements utilisateurs en utilisant des drivers de navigateurs.
</div>

> Fun fact : le saviez vous ? Vous faites des requ√™tes HTTP a chaque fois que vous parcourez des pages web. 


## Tests de charge

<img src="/images/dynamique/loadtest.webp"/>
Les tests de charge permettent d'√©valuer les performances d'un syst√®me, d'une application ou d'un site web en simulant une charge maximale ou une activit√© intense.
L'objectif principal est de d√©terminer comment l'applicatif r√©agit sous une pression ou une charge importante, en termes de temps de r√©ponse, de capacit√© √† g√©rer les demandes et de stabilit√©.
Bien √©videmment on ne peut pas n√©cessairement √™tre aussi proche d'un usage normal qu'en utilisant l'application (on parle alors d'atelier `stress test` ) mais l'objectif est de v√©rifier la capacit√© de mont√©e en charge (nombre d'utilisateur) d'un applicatif.

Il existe une myriade d'outils pour effectuer des tests de charge sur les applicatifs. Dans le monde Java par exemple, l'option Jmeter et sa configuration XML est souvent choisi.


Pour python, il existe quelques projets et nous choisirons d'utiliser `locust` : <a href="https://locust.io/">https://locust.io/</a> qui est un projet assez r√©cent et assez pratique √† prendre en main pour r√©aliser des tests.

Locust permet de d√©finir des **tasks** qui sont des templates de script python que l'on peut ensuite executer au travers d'une application web et faire monter en charge.

```
from locust import HttpUser, between, task

class WebsiteTest(HttpUser):
    wait_time = between(1, 2)
    
    @task
    def index(self):
        self.client.get("/")
```

L'objectif de ces outils de tests de charge est de vous permettre de tester sur des environnements r√©els l'arriv√©e de plus en plus massive d'utilisateur et de suivre les temps de r√©ponse afin de rep√©rer des limites.
<div class="alert alert-info">
  <strong> Pour aller plus loin</strong> <br/> 
Il est de bon ton lorsqu'on r√©alise ce genre de tests de s'outiller parallelement avec des outils de monitoring. De nombreux outils existent, et en python on pourra par exemple utiliser l'outil <b>sentry</b> :
<a href="https://github.com/getsentry/sentry">https://github.com/getsentry/sentry</a>
</div>

## TP : En repartant de l'API Predicat
Pour tester quelque chose, nous n'allons pas ici s'int√©resser a tester un existant mais bien a d√©velopper une nouvelle fonctionnalit√© pour l'API predicat.

Cette fonctionnalit√© sera une fonctionnalit√© de cache sur la r√©ponse de la pr√©diction, afin de gagner en efficacit√©.

> En informatique moderne, pour r√©pondre a un lot important de requ√™tes utilisateurs, diff√©rentes solutions existent (d√©normalisation, cache)..

L'objectif du cache est de sauvegarder une r√©ponse a une demande existante pour ne pas recalculer la r√©ponse mais simplement renvoyer la r√©ponse pr√©c√©dement √©mise.

Ce que √ßa donne c'est donc, dans le contexte global : d√©finition d'un dictionnaire. Et alimentation de ce dictionnaire pendant le run et bypass de fonction si cela a d√©j√† √©t√© calcul√©.

> Exemple basique :
```python
cache = {}
def get_in_cache_else_return(function_call, function_name, argument):
    cache_key=f"{function_name}-{argument}"
    if cache_key in cache:
        print("cache exists")
        return cache[cache_key]
    else:
        cache[cache_key] = function_call
        return cache[cache_key]

def a(b:int):
    return b+1

print(get_in_cache_else_return(a(1),"a","b"))
# 3
print(get_in_cache_else_return(a(1),"a","b"))
# Cache exist | 3
```
### Exercice 1 : Refactor pour ajout de la fonctionnalit√© de cache
Cette partie est l√† pour vous montrer l'id√©e d'un refactor.

- Dans le fichier `main.py`
 
- 1 - On va faire un petit refactor : on va prendre l'int√©gralit√© du code ici :
```python
    if n == "all":
        n = [i for i in config["models"]]
    if type(n) == str:
        n = [n]
    output = {}

    for nomenclature in n:
        output[nomenclature] = {}
        descriptions = sorted(set(q), key=q.index)
        preprocessed_descriptions = [
            preprocess_text(description) for description in descriptions
        ]
        preds = predict_using_model(
            preprocessed_descriptions, model=models[nomenclature], k=k
        )
        if v:
            for pred in preds:
                for pred_k in pred:
                    pred_k["label"] += " | " + full_dict.get(pred_k["label"], "")
        for description, pred in zip(descriptions, preds):
            output[nomenclature][description] = pred

```

Et le d√©placer dans une fonction d√©di√©e : 

```python
def predict_label_core(q:str,k:int,v:Optional[bool],n:Literal["na2008", "coicop", "na2008_old", "all"]):
    if n == "all":
        n = [i for i in config["models"]]
    if type(n) == str:
        n = [n]
    output = {}

    for nomenclature in n:
        output[nomenclature] = {}
        descriptions = sorted(set(q), key=q.index)
        preprocessed_descriptions = [
            preprocess_text(description) for description in descriptions
        ]
        preds = predict_using_model(
            preprocessed_descriptions, model=models[nomenclature], k=k
        )
        if v:
            for pred in preds:
                for pred_k in pred:
                    pred_k["label"] += " | " + full_dict.get(pred_k["label"], "")
        for description, pred in zip(descriptions, preds):
            output[nomenclature][description] = pred
```

Ainsi :  

```
async def predict_label(
    q: List[str] = Query(
        ...,
        title="query string",
        description="Description of the product to be classified",
    ),
    k: int = Query(
        1, title="top-K", description="Specify number of predictions to be displayed"
    ),
    v: Optional[bool] = Query(
        False, title="verbosity", description="If True, add the label of code category"
    ),
    n: Literal["na2008", "coicop", "na2008_old", "all"] = Query(
        "all", title="nomenclature", description="Classification system desired"
    ),
):
    if n == "all":
        n = [i for i in config["models"]]
    if type(n) == str:
        n = [n]
    output = {}

    for nomenclature in n:
        output[nomenclature] = {}
        descriptions = sorted(set(q), key=q.index)
        preprocessed_descriptions = [
            preprocess_text(description) for description in descriptions
        ]
        preds = predict_using_model(
            preprocessed_descriptions, model=models[nomenclature], k=k
        )
        if v:
            for pred in preds:
                for pred_k in pred:
                    pred_k["label"] += " | " + full_dict.get(pred_k["label"], "")
        for description, pred in zip(descriptions, preds):
            output[nomenclature][description] = pred

    return output
```

devient :

```python
async def predict_label(
    q: List[str] = Query(
        ...,
        title="query string",
        description="Description of the product to be classified",
    ),
    k: int = Query(
        1, title="top-K", description="Specify number of predictions to be displayed"
    ),
    v: Optional[bool] = Query(
        False, title="verbosity", description="If True, add the label of code category"
    ),
    n: Literal["na2008", "coicop", "na2008_old", "all"] = Query(
        "all", title="nomenclature", description="Classification system desired"
    ),
):
    return predict_label_core(q=q,k=k,v=v,n=n)
```

Ensuite il faut qu'on fasse notre cache : 
Dans un fichier a c√¥t√© `cache_manager.py` dans le dossier **app**
```python
class CacheManager:

    """
    classe simple qui permet, de stocker des r√©sultats
    """
    def __init__(self):
        self.cache = {}

    def get_in_cache_else_return(self,function_call, function_name, argument):
        """
        Appelle une fonction si son nom et l'argument pr√©cis√© n'a pas d√©j√† √©t√© utilis√©
        Sinon va chercher dans le dictionnaire Cache la valeur stock√©e lors d'un pr√©c√©dent appel de fonction
        """
        cache_key=f"{function_name}-{argument}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        else:
            self.cache[cache_key] = function_call
        return self.cache[cache_key]
```
```python
cache_manager = CacheManager()
async def predict_label(
    q: List[str] = Query(
        ...,
        title="query string",
        description="Description of the product to be classified",
    ),
    k: int = Query(
        1, title="top-K", description="Specify number of predictions to be displayed"
    ),
    v: Optional[bool] = Query(
        False, title="verbosity", description="If True, add the label of code category"
    ),
    n: Literal["na2008", "coicop", "na2008_old", "all"] = Query(
        "all", title="nomenclature", description="Classification system desired"
    ),
):
    return cache_manager.get_in_cache_else_return(predict_label_core(q=q,k=k,v=v,n=n),"predict_label_core",q)
```
### Exercice 2 : Validation par impl√©mentation d'un test unitaire

La fonction de cache comme vu dans l'exemple plus haut, se teste ind√©pendamment de la fonction appel√©e si non pr√©sent dans le cache.

- Impl√©mentez un test avec une fonction que vous d√©velopperez pour v√©rifier que le cache_manager est fonctionnel


<details><summary><b>AIDE 1 (clickable): Aide avec spoiler </b></summary>
<p>

√ßa donne un truc du genre avec une fonction mock
```python
from unittest import TestCase
from predicat.app.cache_manager import CacheManager
from unittest.mock import Mock

class TestCache(TestCase):
    def test_cache_manager_ok(self):
        """
        creation d'une mock fonction qui renvoie 1 puis 2 et verification que √ßa renvoie 2 fois 1
        """
        mock_function = Mock(side_effect=[1,2])
        cache_manager = CacheManager()
        self.assertEqual(1,cache_manager.get_in_cache_else_return(mock_function(),"mock_func",None))
        self.assertEqual(1,cache_manager.get_in_cache_else_return(mock_function(), "mock_func", None))

```

> On notera bien qu'il y a un probl√®me avec le fait que la fonction d√©pend du contexte et donc il manque l'impl√©mentation d'une fonction statique.

</p></details>

### Exercice 3 - Mont√©e en charge de l'API

S'exercer sur locust a partir de la documentation disponible ici : 

https://docs.locust.io/en/stable/index.html


- 1. `pip install locust`
- 2. https://docs.locust.io/en/stable/writing-a-locustfile.html

<details><summary><b>Solution clickable </b></summary>
<p>

```python
from locust import HttpUser, task, between

class ConfitureUser(HttpUser):
    wait_time = between(1, 5)

    @task
    def get_confiture(self):
        self.client.get("/label?q=confiture")
```

</p></details>

- 3. D√©marrer l'api si elle n'est plus disponible

- 4. Requ√™ter en augmentant la charge, l'url

<details><summary><b>Solution clickable </b></summary>
<p>

```
locust -f LEFICHIERQUEVOUSAVEZCREE
```

</p></details>

Testez ensuite sur votre application lanc√©e en local en mode **headless**


<details><summary><b>Solution clickable </b></summary>
<p>

```
locust --headless --users 10 --spawn-rate 1 -H http://localhost:8000 -f LEFICHIERQUEVOUSAVEZCREE
```

</p></details>


<a href="https://docs.locust.io/en/stable/quickstart.html#direct-command-line-usage-headless">https://docs.locust.io/en/stable/quickstart.html#direct-command-line-usage-headless</a>